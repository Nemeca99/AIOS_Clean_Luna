#!/usr/bin/env python3
"""
AIOS FILE STANDARDS SYSTEM
Comprehensive file format standards and auto-checking for AIOS project consistency.
"""

import os
import re
import json
import ast
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime
import subprocess
import sys

class FileType(Enum):
    """AIOS supported file types"""
    PYTHON = "python"
    JSON = "json"
    POWERSHELL = "powershell"
    MARKDOWN = "markdown"
    BATCH = "batch"
    CONFIG = "config"
    DOCUMENTATION = "documentation"

class SeverityLevel(Enum):
    """Issue severity levels"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class FileStandard:
    """File standard definition"""
    file_type: FileType
    required_header: str
    max_line_length: int
    required_imports: List[str]
    forbidden_patterns: List[str]
    required_patterns: List[str]
    encoding: str
    line_ending: str
    indent_size: int
    docstring_required: bool
    type_hints_required: bool
    error_handling_required: bool

@dataclass
class ValidationIssue:
    """File validation issue"""
    file_path: str
    line_number: int
    column: int
    issue_type: str
    severity: SeverityLevel
    message: str
    suggested_fix: str
    auto_fixable: bool

@dataclass
class FileValidationResult:
    """Complete file validation result"""
    file_path: str
    file_type: FileType
    is_valid: bool
    issues: List[ValidationIssue]
    checksum: str
    last_modified: datetime
    standards_compliance: float
    auto_fixable_issues: int
    manual_fix_required: int

class AIOSFileStandards:
    """AIOS File Standards Configuration and Validation"""
    
    # === PYTHON STANDARDS ===
    PYTHON_STANDARD = FileStandard(
        file_type=FileType.PYTHON,
        required_header="""#!/usr/bin/env python3
\"\"\"
{module_name}
{description}
\"\"\"""",
        max_line_length=88,
        required_imports=[
            "sys",
            "pathlib.Path",
            "utils.unicode_safe_output"
        ],
        forbidden_patterns=[
            r"import \*",  # No wildcard imports
            r"print\(",   # No print statements (use logging)
            r"except:",   # No bare except clauses
            r"PLACEHOLDER_COMMENT_PATTERN",  # Pattern for finding unfinished work
        ],
        required_patterns=[
            r"# CRITICAL: Import Unicode safety layer FIRST",
            r"from utils\.unicode_safe_output import setup_unicode_safe_output",
            r"setup_unicode_safe_output\(\)",
            r"class \w+.*:",  # Classes must be defined
            r"def \w+.*:",   # Functions must be defined
            r"\"\"\".*\"\"\"",  # Docstrings required
        ],
        encoding="utf-8",
        line_ending="\n",
        indent_size=4,
        docstring_required=True,
        type_hints_required=True,
        error_handling_required=True
    )
    
    # === JSON STANDARDS ===
    JSON_STANDARD = FileStandard(
        file_type=FileType.JSON,
        required_header="",  # JSON doesn't support headers
        max_line_length=120,
        required_imports=[],  # Not applicable
        forbidden_patterns=[
            r"\"id\":\s*null",  # IDs must not be null
            r"\"timestamp\":\s*\"\"",  # Timestamps must not be empty
        ],
        required_patterns=[
            r"\[",  # Must be JSON array format
            r"\"id\":\s*\"[^\"]+\"",  # Must have ID field
            r"\"timestamp\":\s*\"[^\"]+\"",  # Must have timestamp
        ],
        encoding="utf-8",
        line_ending="\n",
        indent_size=2,
        docstring_required=False,
        type_hints_required=False,
        error_handling_required=False
    )
    
    # === POWERSHELL STANDARDS ===
    POWERSHELL_STANDARD = FileStandard(
        file_type=FileType.POWERSHELL,
        required_header="""# AIOS PowerShell Backend Monitor
# {description}
# Generated: {timestamp}
# Author: AIOS System""",
        max_line_length=120,
        required_imports=[],  # Not applicable for PowerShell
        forbidden_patterns=[
            r"Write-Host",  # Use Write-AIOSMessage instead
            r"Write-Output",  # Use Write-AIOSMessage instead
            r"echo ",  # Use Write-AIOSMessage instead
        ],
        required_patterns=[
            r"Write-AIOSMessage",  # Must use AIOS logging
            r"param\(",  # Must have parameter block
            r"function \w+.*{",  # Functions must be properly defined
        ],
        encoding="utf-8",
        line_ending="\r\n",
        indent_size=4,
        docstring_required=False,
        type_hints_required=False,
        error_handling_required=True
    )
    
    # === MARKDOWN STANDARDS ===
    MARKDOWN_STANDARD = FileStandard(
        file_type=FileType.MARKDOWN,
        required_header="""# {title}
**Date:** {date}  
**Status:** {status}

## Overview
{description}
""",
        max_line_length=100,
        required_imports=[],  # Not applicable
        forbidden_patterns=[
            r"<script",  # No JavaScript in markdown
            r"javascript:",  # No JavaScript URLs
        ],
        required_patterns=[
            r"^#\s+",  # Must have at least one header
            r"##\s+",  # Must have subsections
        ],
        encoding="utf-8",
        line_ending="\n",
        indent_size=0,
        docstring_required=False,
        type_hints_required=False,
        error_handling_required=False
    )
    
    # === CONFIG STANDARDS ===
    CONFIG_STANDARD = FileStandard(
        file_type=FileType.CONFIG,
        required_header="""# AIOS Configuration File
# {config_type}
# Version: {version}
# Generated: {timestamp}
""",
        max_line_length=120,
        required_imports=[],  # Not applicable
        forbidden_patterns=[
            r"password\s*=",  # No plaintext passwords
            r"secret\s*=",   # No plaintext secrets
            r"key\s*=",     # No plaintext keys
        ],
        required_patterns=[
            r"version\s*=",  # Must have version
            r"timestamp\s*=",  # Must have timestamp
        ],
        encoding="utf-8",
        line_ending="\n",
        indent_size=4,
        docstring_required=False,
        type_hints_required=False,
        error_handling_required=False
    )

class AIOSFileValidator:
    """AIOS File Validation Engine"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.standards = {
            FileType.PYTHON: AIOSFileStandards.PYTHON_STANDARD,
            FileType.JSON: AIOSFileStandards.JSON_STANDARD,
            FileType.POWERSHELL: AIOSFileStandards.POWERSHELL_STANDARD,
            FileType.MARKDOWN: AIOSFileStandards.MARKDOWN_STANDARD,
            FileType.CONFIG: AIOSFileStandards.CONFIG_STANDARD,
        }
        self.validation_cache = {}
    
    def detect_file_type(self, file_path: Path) -> FileType:
        """Detect file type based on extension and content"""
        suffix = file_path.suffix.lower()
        
        if suffix == '.py':
            return FileType.PYTHON
        elif suffix == '.json':
            return FileType.JSON
        elif suffix in ['.ps1', '.psm1']:
            return FileType.POWERSHELL
        elif suffix in ['.md', '.markdown']:
            return FileType.MARKDOWN
        elif suffix in ['.cfg', '.conf', '.ini', '.toml']:
            return FileType.CONFIG
        elif suffix in ['.bat', '.cmd']:
            return FileType.BATCH
        else:
            # Try to detect from content
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    first_line = f.readline().strip()
                    if first_line.startswith('#!/usr/bin/env python3'):
                        return FileType.PYTHON
                    elif first_line.startswith('# AIOS PowerShell'):
                        return FileType.POWERSHELL
                    elif file_path.name.startswith('README'):
                        return FileType.MARKDOWN
            except (IOError, OSError) as e:
                # Can't read file - use extension-based detection
                print(f"Warning: Could not read {file_path} for content detection: {e}")
        
        return FileType.PYTHON  # Default fallback
    
    def validate_file(self, file_path: Union[str, Path]) -> FileValidationResult:
        """Validate a single file against AIOS standards"""
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        file_type = self.detect_file_type(file_path)
        standard = self.standards.get(file_type)
        
        if not standard:
            raise ValueError(f"No standard defined for file type: {file_type}")
        
        # Check cache
        cache_key = f"{file_path}_{file_path.stat().st_mtime}"
        if cache_key in self.validation_cache:
            return self.validation_cache[cache_key]
        
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.splitlines()
        except UnicodeDecodeError:
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=0,
                column=0,
                issue_type="encoding_error",
                severity=SeverityLevel.CRITICAL,
                message="File encoding is not UTF-8",
                suggested_fix="Convert file to UTF-8 encoding",
                auto_fixable=True
            ))
            content = ""
            lines = []
        
        # Validate based on file type
        if file_type == FileType.PYTHON:
            issues.extend(self._validate_python_file(file_path, content, lines, standard))
        elif file_type == FileType.JSON:
            issues.extend(self._validate_json_file(file_path, content, lines, standard))
        elif file_type == FileType.POWERSHELL:
            issues.extend(self._validate_powershell_file(file_path, content, lines, standard))
        elif file_type == FileType.MARKDOWN:
            issues.extend(self._validate_markdown_file(file_path, content, lines, standard))
        elif file_type == FileType.CONFIG:
            issues.extend(self._validate_config_file(file_path, content, lines, standard))
        
        # Calculate compliance score
        total_checks = len(standard.required_patterns) + len(standard.forbidden_patterns) + 5  # Basic checks
        passed_checks = total_checks - len([i for i in issues if i.severity in [SeverityLevel.CRITICAL, SeverityLevel.HIGH]])
        compliance = (passed_checks / total_checks) * 100 if total_checks > 0 else 0
        
        # Create result
        result = FileValidationResult(
            file_path=str(file_path),
            file_type=file_type,
            is_valid=len([i for i in issues if i.severity in [SeverityLevel.CRITICAL, SeverityLevel.HIGH]]) == 0,
            issues=issues,
            checksum=self._calculate_checksum(file_path),
            last_modified=datetime.fromtimestamp(file_path.stat().st_mtime),
            standards_compliance=compliance,
            auto_fixable_issues=len([i for i in issues if i.auto_fixable]),
            manual_fix_required=len([i for i in issues if not i.auto_fixable])
        )
        
        # Cache result
        self.validation_cache[cache_key] = result
        
        return result
    
    def _validate_python_file(self, file_path: Path, content: str, lines: List[str], standard: FileStandard) -> List[ValidationIssue]:
        """Validate Python file against standards"""
        issues = []
        
        # Check header
        if not content.startswith("#!/usr/bin/env python3"):
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=1,
                column=1,
                issue_type="missing_shebang",
                severity=SeverityLevel.HIGH,
                message="Missing Python shebang line",
                suggested_fix="Add '#!/usr/bin/env python3' as first line",
                auto_fixable=True
            ))
        
        # Check Unicode safety import
        if "from utils_core.unicode_safe_output import setup_unicode_safe_output" not in content:
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=0,
                column=0,
                issue_type="missing_unicode_safety",
                severity=SeverityLevel.CRITICAL,
                message="Missing Unicode safety import",
                suggested_fix="Add Unicode safety import and setup call",
                auto_fixable=True
            ))
        
        # Check for forbidden patterns
        for i, line in enumerate(lines, 1):
            for pattern in standard.forbidden_patterns:
                if re.search(pattern, line):
                    issues.append(ValidationIssue(
                        file_path=str(file_path),
                        line_number=i,
                        column=0,
                        issue_type="forbidden_pattern",
                        severity=SeverityLevel.MEDIUM,
                        message=f"Forbidden pattern found: {pattern}",
                        suggested_fix=f"Remove or replace pattern: {pattern}",
                        auto_fixable=False
                    ))
        
        # Check line length
        for i, line in enumerate(lines, 1):
            if len(line) > standard.max_line_length:
                issues.append(ValidationIssue(
                    file_path=str(file_path),
                    line_number=i,
                    column=standard.max_line_length,
                    issue_type="line_too_long",
                    severity=SeverityLevel.MEDIUM,
                    message=f"Line exceeds {standard.max_line_length} characters",
                    suggested_fix="Break line into multiple lines",
                    auto_fixable=False
                ))
        
        # Check for required patterns
        for pattern in standard.required_patterns:
            if not re.search(pattern, content):
                issues.append(ValidationIssue(
                    file_path=str(file_path),
                    line_number=0,
                    column=0,
                    issue_type="missing_required_pattern",
                    severity=SeverityLevel.HIGH,
                    message=f"Missing required pattern: {pattern}",
                    suggested_fix=f"Add required pattern: {pattern}",
                    auto_fixable=False
                ))
        
        # AST-based checks
        try:
            tree = ast.parse(content)
            issues.extend(self._validate_python_ast(file_path, tree))
        except SyntaxError as e:
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=e.lineno or 0,
                column=e.offset or 0,
                issue_type="syntax_error",
                severity=SeverityLevel.CRITICAL,
                message=f"Python syntax error: {e.msg}",
                suggested_fix="Fix syntax error",
                auto_fixable=False
            ))
        
        return issues
    
    def _validate_python_ast(self, file_path: Path, tree: ast.AST) -> List[ValidationIssue]:
        """Validate Python AST for advanced checks"""
        issues = []
        
        for node in ast.walk(tree):
            # Check for bare except clauses
            if isinstance(node, ast.ExceptHandler) and node.type is None:
                issues.append(ValidationIssue(
                    file_path=str(file_path),
                    line_number=node.lineno,
                    column=node.col_offset,
                    issue_type="bare_except",
                    severity=SeverityLevel.HIGH,
                    message="Bare except clause found",
                    suggested_fix="Specify exception type or use Exception",
                    auto_fixable=False
                ))
            
            # Check for wildcard imports
            if isinstance(node, ast.ImportFrom) and node.names and any(alias.name == '*' for alias in node.names):
                issues.append(ValidationIssue(
                    file_path=str(file_path),
                    line_number=node.lineno,
                    column=node.col_offset,
                    issue_type="wildcard_import",
                    severity=SeverityLevel.MEDIUM,
                    message="Wildcard import found",
                    suggested_fix="Import specific names instead of using *",
                    auto_fixable=False
                ))
            
            # Check for print statements
            if isinstance(node, ast.Call) and isinstance(node.func, ast.Name) and node.func.id == 'print':
                issues.append(ValidationIssue(
                    file_path=str(file_path),
                    line_number=node.lineno,
                    column=node.col_offset,
                    issue_type="print_statement",
                    severity=SeverityLevel.MEDIUM,
                    message="Print statement found",
                    suggested_fix="Use logging instead of print",
                    auto_fixable=False
                ))
        
        return issues
    
    def _validate_json_file(self, file_path: Path, content: str, lines: List[str], standard: FileStandard) -> List[ValidationIssue]:
        """Validate JSON file against standards"""
        issues = []
        
        # Check if it's valid JSON
        try:
            data = json.loads(content)
        except json.JSONDecodeError as e:
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=e.lineno,
                column=e.colno,
                issue_type="invalid_json",
                severity=SeverityLevel.CRITICAL,
                message=f"Invalid JSON: {e.msg}",
                suggested_fix="Fix JSON syntax error",
                auto_fixable=False
            ))
            return issues
        
        # Check if it's an array (AIOS standard)
        if not isinstance(data, list):
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=1,
                column=1,
                issue_type="not_array_format",
                severity=SeverityLevel.HIGH,
                message="JSON must be in array format per AIOS standards",
                suggested_fix="Convert to JSON array format",
                auto_fixable=False
            ))
        
        # Validate array contents
        if isinstance(data, list):
            for i, item in enumerate(data):
                if not isinstance(item, dict):
                    issues.append(ValidationIssue(
                        file_path=str(file_path),
                        line_number=i + 1,
                        column=0,
                        issue_type="invalid_array_item",
                        severity=SeverityLevel.HIGH,
                        message="Array items must be objects",
                        suggested_fix="Convert item to object format",
                        auto_fixable=False
                    ))
                    continue
                
                # Check required fields
                if "id" not in item:
                    issues.append(ValidationIssue(
                        file_path=str(file_path),
                        line_number=i + 1,
                        column=0,
                        issue_type="missing_id",
                        severity=SeverityLevel.HIGH,
                        message="Missing required 'id' field",
                        suggested_fix="Add 'id' field with UUID",
                        auto_fixable=True
                    ))
        
        return issues
    
    def _validate_powershell_file(self, file_path: Path, content: str, lines: List[str], standard: FileStandard) -> List[ValidationIssue]:
        """Validate PowerShell file against standards"""
        issues = []
        
        # Check for AIOS header
        if not content.startswith("# AIOS PowerShell"):
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=1,
                column=1,
                issue_type="missing_aios_header",
                severity=SeverityLevel.MEDIUM,
                message="Missing AIOS PowerShell header",
                suggested_fix="Add AIOS PowerShell header",
                auto_fixable=True
            ))
        
        # Check for forbidden patterns
        for i, line in enumerate(lines, 1):
            for pattern in standard.forbidden_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(ValidationIssue(
                        file_path=str(file_path),
                        line_number=i,
                        column=0,
                        issue_type="forbidden_powershell_pattern",
                        severity=SeverityLevel.MEDIUM,
                        message=f"Forbidden PowerShell pattern: {pattern}",
                        suggested_fix=f"Replace with Write-AIOSMessage",
                        auto_fixable=False
                    ))
        
        return issues
    
    def _validate_markdown_file(self, file_path: Path, content: str, lines: List[str], standard: FileStandard) -> List[ValidationIssue]:
        """Validate Markdown file against standards"""
        issues = []
        
        # Check for headers
        if not re.search(r"^#\s+", content, re.MULTILINE):
            issues.append(ValidationIssue(
                file_path=str(file_path),
                line_number=1,
                column=1,
                issue_type="missing_header",
                severity=SeverityLevel.MEDIUM,
                message="Missing main header",
                suggested_fix="Add main header with #",
                auto_fixable=False
            ))
        
        return issues
    
    def _validate_config_file(self, file_path: Path, content: str, lines: List[str], standard: FileStandard) -> List[ValidationIssue]:
        """Validate config file against standards"""
        issues = []
        
        # Check for forbidden patterns (secrets)
        for i, line in enumerate(lines, 1):
            for pattern in standard.forbidden_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(ValidationIssue(
                        file_path=str(file_path),
                        line_number=i,
                        column=0,
                        issue_type="security_risk",
                        severity=SeverityLevel.CRITICAL,
                        message=f"Security risk: {pattern}",
                        suggested_fix="Use environment variables or encrypted storage",
                        auto_fixable=False
                    ))
        
        return issues
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """Calculate file checksum"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            return "unknown"
    
    def validate_project(self, project_path: str = None) -> Dict[str, FileValidationResult]:
        """Validate entire project against AIOS standards"""
        project_path = Path(project_path) if project_path else self.project_root
        results = {}
        
        # Find all relevant files
        patterns = ['**/*.py', '**/*.json', '**/*.ps1', '**/*.psm1', '**/*.md', '**/*.cfg', '**/*.conf']
        
        for pattern in patterns:
            for file_path in project_path.glob(pattern):
                # Skip certain directories
                if any(part in str(file_path) for part in ['__pycache__', '.git', 'venv', 'node_modules']):
                    continue
                
                try:
                    result = self.validate_file(file_path)
                    results[str(file_path)] = result
                except Exception as e:
                    print(f"Error validating {file_path}: {e}")
        
        return results
    
    def auto_fix_file(self, file_path: Union[str, Path]) -> List[str]:
        """Auto-fix issues in a file"""
        file_path = Path(file_path)
        result = self.validate_file(file_path)
        
        fixes_applied = []
        
        for issue in result.issues:
            if not issue.auto_fixable:
                continue
            
            if issue.issue_type == "missing_shebang" and file_path.suffix == '.py':
                # Add shebang
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if not content.startswith("#!/usr/bin/env python3"):
                    new_content = "#!/usr/bin/env python3\n" + content
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    fixes_applied.append("Added Python shebang")
            
            elif issue.issue_type == "missing_unicode_safety" and file_path.suffix == '.py':
                # Add Unicode safety import
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if "from utils_core.unicode_safe_output import setup_unicode_safe_output" not in content:
                    lines = content.split('\n')
                    # Insert after shebang and docstring
                    insert_line = 1
                    while insert_line < len(lines) and (lines[insert_line].strip().startswith('#') or lines[insert_line].strip().startswith('"""')):
                        insert_line += 1
                    
                    lines.insert(insert_line, "")
                    lines.insert(insert_line + 1, "# CRITICAL: Import Unicode safety layer FIRST to prevent encoding errors")
                    lines.insert(insert_line + 2, "import sys")
                    lines.insert(insert_line + 3, "from pathlib import Path")
                    lines.insert(insert_line + 4, "sys.path.append(str(Path(__file__).parent.parent))")
                    lines.insert(insert_line + 5, "from utils_core.unicode_safe_output import setup_unicode_safe_output")
                    lines.insert(insert_line + 6, "setup_unicode_safe_output()")
                    lines.insert(insert_line + 7, "")
                    
                    new_content = '\n'.join(lines)
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    fixes_applied.append("Added Unicode safety imports")
            
            elif issue.issue_type == "encoding_error":
                # Fix encoding
                try:
                    with open(file_path, 'r', encoding='latin-1') as f:
                        content = f.read()
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    fixes_applied.append("Fixed file encoding to UTF-8")
                except (IOError, OSError, UnicodeDecodeError) as e:
                    # Can't fix this file - skip it
                    print(f"Warning: Could not fix encoding for {file_path}: {e}")
        
        return fixes_applied

class AIOSStandardsManager:
    """AIOS Standards Management and Enforcement"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.validator = AIOSFileValidator(self.project_root)
        self.standards_file = self.project_root / "AIOS_STANDARDS.md"
    
    def generate_standards_documentation(self) -> str:
        """Generate comprehensive standards documentation"""
        doc = """# AIOS FILE STANDARDS DOCUMENTATION

## ðŸŽ¯ Core Principle
**All AIOS files must follow strict internal standards for consistency, modularity, and maintainability.**

## ðŸ“‹ File Type Standards

### Python Files (.py)
- **Header**: Must start with `#!/usr/bin/env python3`
- **Unicode Safety**: Must import and setup Unicode safety layer
- **Line Length**: Maximum 88 characters (Black standard)
- **Indentation**: 4 spaces (no tabs)
- **Imports**: No wildcard imports (`import *`)
- **Error Handling**: Must handle exceptions properly
- **Logging**: Use logging instead of print statements
- **Type Hints**: Required for all functions and methods
- **Docstrings**: Required for all classes and functions

**Required Import Pattern:**
```python
#!/usr/bin/env python3
\"\"\"
Module Name
Description
\"\"\"

# CRITICAL: Import Unicode safety layer FIRST to prevent encoding errors
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from utils_core.unicode_safe_output import setup_unicode_safe_output
setup_unicode_safe_output()

# Other imports...
```

### JSON Files (.json)
- **Format**: Must use JSON array format `[{}, {}, {}]`
- **Required Fields**: All objects must have `id` and `timestamp`
- **Encoding**: UTF-8
- **Indentation**: 2 spaces
- **Validation**: Must pass AIOS JSON standards validation

**Required Structure:**
```json
[
  {
    "id": "uuid-string",
    "timestamp": "2025-01-01T00:00:00.000Z",
    "data": "value"
  }
]
```

### PowerShell Files (.ps1, .psm1)
- **Header**: Must start with `# AIOS PowerShell`
- **Logging**: Must use `Write-AIOSMessage` instead of `Write-Host`
- **Parameters**: Must have parameter block
- **Functions**: Must be properly defined with braces
- **Encoding**: UTF-8 with BOM
- **Line Endings**: CRLF

**Required Header:**
```powershell
# AIOS PowerShell Backend Monitor
# Description
# Generated: 2025-01-01
# Author: AIOS System

param(
    [Parameter(Mandatory=$false)]
    [string]$Parameter1
)
```

### Markdown Files (.md)
- **Headers**: Must have main header and subsections
- **Structure**: Must follow AIOS documentation format
- **Security**: No JavaScript or external scripts
- **Line Length**: Maximum 100 characters

### Configuration Files (.cfg, .conf, .ini)
- **Security**: No plaintext passwords or secrets
- **Versioning**: Must include version and timestamp
- **Format**: Follow standard format conventions

## ðŸ”§ Validation Rules

### Critical Issues (Must Fix)
- Missing Unicode safety imports (Python)
- Invalid JSON syntax
- Security risks (plaintext secrets)
- Syntax errors

### High Priority Issues
- Missing required headers
- Non-array JSON format
- Missing required fields
- Bare except clauses

### Medium Priority Issues
- Line length violations
- Forbidden patterns
- Missing docstrings
- Wildcard imports

### Low Priority Issues
- Style violations
- Minor formatting issues
- Optional pattern violations

## ðŸš€ Auto-Fix Capabilities

The system can automatically fix:
- Add missing Python shebang
- Add Unicode safety imports
- Fix file encoding to UTF-8
- Add missing JSON IDs
- Fix basic formatting issues

## ðŸ“Š Compliance Scoring

Files are scored on:
- **Critical Issues**: 0 points (must fix)
- **High Issues**: -20 points each
- **Medium Issues**: -10 points each
- **Low Issues**: -5 points each
- **Perfect Compliance**: 100 points

## ðŸ› ï¸ Usage

### Command Line
```bash
# Validate single file
python utils/aios_file_standards.py validate file.py

# Validate entire project
python utils/aios_file_standards.py validate-project

# Auto-fix issues
python utils/aios_file_standards.py auto-fix file.py
```

### Python API
```python
from utils_core.aios_file_standards import AIOSFileValidator

validator = AIOSFileValidator()
result = validator.validate_file("file.py")
print(f"Compliance: {result.standards_compliance}%")

# Auto-fix issues
fixes = validator.auto_fix_file("file.py")
print(f"Applied fixes: {fixes}")
```

## ðŸ“ˆ Integration with CI/CD

The standards system integrates with:
- **Pre-commit hooks**: Automatic validation before commits
- **GitHub Actions**: Automated validation in CI pipeline
- **IDE plugins**: Real-time validation in development
- **Build system**: Validation as part of build process

## ðŸŽ¯ Benefits

1. **Consistency**: All files follow the same standards
2. **Maintainability**: Easy to read and modify
3. **Security**: Prevents common security issues
4. **Quality**: Catches issues early
5. **Automation**: Reduces manual review time
6. **Modularity**: Ensures proper module structure

---
**This standard ensures all AIOS components maintain internal consistency and quality!** ðŸš€
"""
        return doc
    
    def save_standards_documentation(self):
        """Save standards documentation to file"""
        doc = self.generate_standards_documentation()
        with open(self.standards_file, 'w', encoding='utf-8') as f:
            f.write(doc)
        print(f"Standards documentation saved to: {self.standards_file}")
    
    def validate_project_with_report(self) -> Dict[str, Any]:
        """Validate entire project and generate report"""
        results = self.validator.validate_project()
        
        # Generate summary statistics
        total_files = len(results)
        valid_files = len([r for r in results.values() if r.is_valid])
        critical_issues = sum(len([i for i in r.issues if i.severity == SeverityLevel.CRITICAL]) for r in results.values())
        high_issues = sum(len([i for i in r.issues if i.severity == SeverityLevel.HIGH]) for r in results.values())
        medium_issues = sum(len([i for i in r.issues if i.severity == SeverityLevel.MEDIUM]) for r in results.values())
        low_issues = sum(len([i for i in r.issues if i.severity == SeverityLevel.LOW]) for r in results.values())
        
        avg_compliance = sum(r.standards_compliance for r in results.values()) / total_files if total_files > 0 else 0
        
        report = {
            "summary": {
                "total_files": total_files,
                "valid_files": valid_files,
                "invalid_files": total_files - valid_files,
                "average_compliance": avg_compliance,
                "critical_issues": critical_issues,
                "high_issues": high_issues,
                "medium_issues": medium_issues,
                "low_issues": low_issues
            },
            "files": {path: asdict(result) for path, result in results.items()},
            "timestamp": datetime.now().isoformat()
        }
        
        return report

def main():
    """Main CLI interface for AIOS File Standards"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AIOS File Standards Validator")
    parser.add_argument("command", choices=["validate", "validate-project", "auto-fix", "generate-docs"], 
                       help="Command to execute")
    parser.add_argument("file", nargs="?", help="File to validate or fix")
    parser.add_argument("--project-root", help="Project root directory")
    
    args = parser.parse_args()
    
    manager = AIOSStandardsManager(args.project_root)
    
    if args.command == "validate" and args.file:
        result = manager.validator.validate_file(args.file)
        print(f"File: {args.file}")
        print(f"Valid: {result.is_valid}")
        print(f"Compliance: {result.standards_compliance:.1f}%")
        print(f"Issues: {len(result.issues)}")
        
        for issue in result.issues:
            print(f"  {issue.severity.value.upper()}: {issue.message} (Line {issue.line_number})")
    
    elif args.command == "validate-project":
        report = manager.validate_project_with_report()
        print("AIOS Project Validation Report")
        print("=" * 40)
        print(f"Total Files: {report['summary']['total_files']}")
        print(f"Valid Files: {report['summary']['valid_files']}")
        print(f"Average Compliance: {report['summary']['average_compliance']:.1f}%")
        print(f"Critical Issues: {report['summary']['critical_issues']}")
        print(f"High Issues: {report['summary']['high_issues']}")
        
        # Save detailed report
        report_file = manager.project_root / "validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, default=str)
        print(f"Detailed report saved to: {report_file}")
    
    elif args.command == "auto-fix" and args.file:
        fixes = manager.validator.auto_fix_file(args.file)
        if fixes:
            print(f"Applied fixes to {args.file}:")
            for fix in fixes:
                print(f"  - {fix}")
        else:
            print("No auto-fixable issues found")
    
    elif args.command == "generate-docs":
        manager.save_standards_documentation()
        print("Standards documentation generated")

if __name__ == "__main__":
    main()
