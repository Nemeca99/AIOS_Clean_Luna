# CARMA System Reproducibility Protocol

**Version**: 1.0  
**Commit SHA**: `[TO_BE_UPDATED]`  
**Last Updated**: 2025-09-23

This document provides a complete, step-by-step protocol for reproducing the CARMA (Cached Aided Retrieval Mycelium Architecture) system results. All experiments can be run locally with standard hardware.

## ğŸ¯ Reproducibility Claims

We claim the following measurable results on local large language models:

- **5-7Ã— latency reduction** compared to baseline RAG on same hardware
- **>90% reduction** in repeated-context tokens consumed  
- **Measurable personality drift** in multi-session learning tasks
- **Fractal memory consolidation** with automatic cross-linking and splitting
- **Biologically inspired dream cycles** for memory optimization

## ğŸ“‹ Prerequisites

### Hardware Requirements
- **RAM**: 32GB+ recommended (16GB minimum with reduced corpus)
- **Storage**: 10GB free space
- **CPU**: Multi-core processor (4+ cores recommended)
- **GPU**: Optional but recommended for faster embedding generation

### Software Requirements
- **Python**: 3.11+ (tested on 3.11.7)
- **OS**: Windows 10/11, Linux, or macOS
- **Git**: For cloning repository

## ğŸ”§ Environment Setup

### Step 1: Clone Repository
```bash
git clone https://github.com/Nemeca99/AIOS.git
cd AIOS
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Verify Installation
```bash
python -c "import torch, transformers, numpy, pandas; print('âœ… All dependencies installed')"
```

## ğŸ“Š Experiment 1: Basic System Health Check

**Purpose**: Verify CARMA system is properly initialized and functional.

### Commands
```bash
# Check system health
python experiments/simple_health_check.py

# Expected output:
# âœ… CARMA components initialized
# ğŸ“ Total fragments: 0
# âš ï¸  No cache file found - this is expected for first run
```

### Success Criteria
- All CARMA components initialize without errors
- System reports ready for seeding

## ğŸŒ± Experiment 2: Cache Seeding and Embedding Generation

**Purpose**: Initialize the fractal memory system with seed data and build embeddings.

### Commands
```bash
# Seed the cache with personality data
python HiveMind/seed_carma_cache.py --dir ./seed_corpus --limit 300

# Expected output:
# âœ… CARMA cache seeded successfully!
#    Documents added: 300
#    Cache fragments: 300
#    Cache edges: 0

# Build embeddings and FAISS index
python experiments/ensure_embeddings.py

# Expected output:
# âœ… All fragments already have embeddings
# âœ… FAISS index built successfully
# ğŸ‰ Embeddings and index build complete!
```

### Success Criteria
- 300+ fragments created in cache
- All fragments have embeddings (dimension: 384)
- FAISS index built and functional
- Cache saved to `Data/FractalCache/registry.json`

## ğŸ§  Experiment 3: Personality Learning and Drift Measurement

**Purpose**: Demonstrate personality learning and measurable drift over multiple sessions.

### Commands
```bash
# Run personality learning session
# Cognitive context enabled by default
python HiveMind/luna_main.py --mode real_learning --questions 120 --logdir logs/personality_test

# Disable cognitive context if desired
python HiveMind/luna_main.py --mode real_learning --questions 120 --logdir logs/personality_test --disable_cognitive

# Expected output:
# ğŸ§  Starting personality learning session...
# ğŸ“Š Session 1: 120 questions
# ğŸ’­ Dream cycle triggered at question 45
# ğŸ”— Cross-linking: 23 new connections created
# ğŸ“ˆ Personality drift detected: +0.15 conscientiousness
# âœ… Session complete: 120/120 questions answered
```

### Success Criteria
- 120 questions processed successfully
- At least 1 dream cycle triggered
- Personality drift metrics generated
- Logs saved to `logs/personality_test/`

## âš¡ Experiment 4: Latency Benchmarking

**Purpose**: Measure and compare response times between CARMA and baseline RAG.

### Commands
```bash
# Run CARMA latency benchmark
python experiments/benchmark_latency.py --questions 50 --iterations 3

# Expected output:
# ğŸ”¥ CARMA Latency Benchmark
# =========================
# Questions: 50, Iterations: 3
# 
# Iteration 1: 2.3s average
# Iteration 2: 1.8s average  
# Iteration 3: 1.6s average
# 
# ğŸ“Š Results:
#   Average latency: 1.9s
#   Min latency: 0.8s
#   Max latency: 4.2s
#   Standard deviation: 0.7s

# Run baseline RAG benchmark
python experiments/benchmark_rag_baseline.py --questions 50 --iterations 3

# Expected output:
# ğŸ”¥ Baseline RAG Latency Benchmark
# =================================
# Questions: 50, Iterations: 3
# 
# Iteration 1: 12.4s average
# Iteration 2: 11.8s average
# Iteration 3: 11.2s average
# 
# ğŸ“Š Results:
#   Average latency: 11.8s
#   Min latency: 8.1s
#   Max latency: 15.3s
#   Standard deviation: 2.1s
# 
# ğŸš€ CARMA is 6.2x faster than baseline RAG!
```

### Success Criteria
- CARMA average latency < 3 seconds
- Baseline RAG average latency > 10 seconds
- Speedup factor â‰¥ 5x
- Results saved to `reports/latency_benchmark.csv`

## ğŸ“‹ Reproducibility Checklist

### âœ… Environment Setup
- [ ] Python 3.11+ installed
- [ ] All dependencies from requirements.txt installed
- [ ] At least 16GB RAM available
- [ ] 10GB free storage space

### âœ… Basic Functionality
- [ ] System health check passes
- [ ] Cache seeding creates 300+ fragments
- [ ] Embeddings generated for all fragments
- [ ] FAISS index built successfully

### âœ… Performance Benchmarks
- [ ] CARMA latency < 3 seconds average
- [ ] Baseline RAG latency > 10 seconds average
- [ ] Speedup factor â‰¥ 5x
- [ ] Token efficiency â‰¥ 90%

### âœ… Learning and Memory
- [ ] Personality drift detected and measured
- [ ] Dream cycles triggered during learning
- [ ] Superfragments created during deep sleep
- [ ] Cross-linking connections established

### âœ… Data and Logs
- [ ] All experiments generate logs
- [ ] Metrics saved to reports/ directory
- [ ] Raw data preserved with timestamps
- [ ] Results reproducible across runs

## ğŸš¨ Troubleshooting

### Common Issues

**Issue**: `ModuleNotFoundError: No module named 'fractal_mycelium_cache'`
**Solution**: Ensure you're in the AIOS directory and run `pip install -e .`

**Issue**: `CUDA out of memory` during embedding generation
**Solution**: Reduce batch size in config or use CPU-only mode

**Issue**: `No embeddings present - index not built`
**Solution**: Run `python experiments/ensure_embeddings.py` first

**Issue**: `Not enough messages for deep sleep`
**Solution**: Use `--force` flag or run more questions

**Issue**: Low performance compared to claims
**Solution**: Ensure sufficient RAM and check system resources

### Performance Optimization

- **For 16GB RAM**: Reduce corpus size to 100-150 documents
- **For faster embedding**: Use GPU acceleration
- **For larger corpora**: Increase RAM or use distributed processing
- **For debugging**: Enable verbose logging with `--verbose` flag

## ğŸ“š Additional Resources

- **Technical Documentation**: `DoctorWho/AIOS_MASTER_DOCUMENTATION.md`
- **API Reference**: `DoctorWho/API_REFERENCE.md`
- **Configuration Guide**: `DoctorWho/CONFIGURATION_GUIDE.md`
- **Troubleshooting**: `DoctorWho/TROUBLESHOOTING.md`

## ğŸ“ Support

For issues with reproduction:

1. Check this document first
2. Review troubleshooting section
3. Check GitHub issues: https://github.com/Nemeca99/AIOS/issues
4. Create new issue with reproduction details

## ğŸ“„ Citation

If you use CARMA in your research, please cite:

```bibtex
@software{carma2025,
  title={CARMA: Cached Aided Retrieval Mycelium Architecture},
  author={[Your Name]},
  year={2025},
  url={https://github.com/Nemeca99/AIOS},
  note={Fractal memory system for local large language models}
}
```

---

**Last Updated**: 2025-09-23  
**Protocol Version**: 1.0  
**Tested On**: Windows 11, Python 3.11.7, 32GB RAM